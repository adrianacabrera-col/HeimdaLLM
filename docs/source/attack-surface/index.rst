🛡️ Attack Surface
=================

:term:`LLMs <LLM>` are vulnerable to :term:`prompt injection` attacks, which can be used
to construct responses that are dangerous to the system. This is the primary reason that
LLMs have not seen widespread adoption as :term:`externalized <externalizing>` products.

Prompt injection can have different consequences for different types of structured
outputs.

.. toctree::
    :glob:

    sql